{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_erwann_history = \"data/erwann_full.csv\"\n",
    "raw_irfan_history = \"data/irfan.csv\"\n",
    "raw_kaggle_data = \"data/urldata.csv\"\n",
    "\n",
    "unique_irfan_history = \"data/unique_irfan.csv\"\n",
    "unique_erwann_history = \"data/unique_erwann_history\"\n",
    "\n",
    "kaggle_set_folder = \"data/kaggle_set_folder\"\n",
    "kaggle_test_set_folder = \"data/kaggle_test_set_folder\"\n",
    "\n",
    "small_kaggle_set_folder = \"data/small_kaggle_set_folder\"\n",
    "small_kaggle_test_set_folder = \"data/small_kaggle_test_set_folder\"\n",
    "\n",
    "history_set_folder = \"data/history_set_folder\"\n",
    "history_test_set_folder = \"data/history_test_set_folder\"\n",
    "\n",
    "combine_set_folder = \"data/combined_set_folder\"\n",
    "combine_test_set_folder = \"data/combined_test_set_folder\"\n",
    "\n",
    "valid_folder_name = \"valid\"\n",
    "malicious_folder_name = \"malicious\"\n",
    "\n",
    "SEED = 42\n",
    "PADDING_SIZE = 75\n",
    "HISTORY_TRAIN_RATION = 0.9\n",
    "\n",
    "pad = \"\"\n",
    "for i in range(PADDING_SIZE):\n",
    "    pad = pad + \" \""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-53286fa91900>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  kaggle_data[\"url\"][i] = kaggle_data[\"url\"][i][:PADDING_SIZE]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 done\n",
      "20000 done\n",
      "30000 done\n",
      "40000 done\n",
      "50000 done\n",
      "60000 done\n",
      "KAGGLE SET PADDING DONE\n",
      "100000 done\n",
      "200000 done\n",
      "300000 done\n",
      "400000 done\n",
      "KAGGLE SMALL DATASET DONE\n"
     ]
    }
   ],
   "source": [
    "kaggle_data = pd.read_csv(raw_kaggle_data)\n",
    "kaggle_data = kaggle_data.drop('Unnamed: 0', axis=1)\n",
    "kaggle_data = kaggle_data.drop('label', axis=1)\n",
    "\n",
    "kaggle_data = kaggle_data.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "#Pad Kaggle_dataset\n",
    "kaggle_data = kaggle_data.copy()\n",
    "kaggle_data[\"url\"] = kaggle_data[\"url\"].str.pad(width=PADDING_SIZE, side='right', fillchar=' ')\n",
    "for i in range(len(kaggle_data)):\n",
    "    if i < 65000:\n",
    "        if len(kaggle_data[\"url\"][i]) > PADDING_SIZE:\n",
    "            kaggle_data[\"url\"][i] = kaggle_data[\"url\"][i][:PADDING_SIZE]\n",
    "        if i % 10000 == 0:\n",
    "            print(str(i) + \" done\")\n",
    "print(\"KAGGLE SET PADDING DONE\")\n",
    "\n",
    "#Create small_kaggle_dataset\n",
    "i = 0\n",
    "valid = 0\n",
    "malicious = 0\n",
    "test = 0\n",
    "malicious_test = 0\n",
    "valid_test = 0\n",
    "for index, row in kaggle_data.iterrows():\n",
    "    if malicious > 10000 and valid > 50000 and test > 1200:\n",
    "        break\n",
    "    elif malicious > 10000 and valid > 50000 and test < 1200:\n",
    "        if row[\"result\"] == 1:\n",
    "            if malicious_test > 200:\n",
    "                pass\n",
    "            else:\n",
    "                with open(f\"{small_kaggle_test_set_folder}/{malicious_folder_name}/{malicious_test}.txt\", \"w\") as f:\n",
    "                    f.write(row[\"url\"].replace(\"\", \" \")[1: -1])\n",
    "                malicious_test = malicious_test + 1\n",
    "        else:\n",
    "            if valid_test > 1000:\n",
    "                pass\n",
    "            else:\n",
    "                with open(f\"{small_kaggle_test_set_folder}/{valid_folder_name}/{valid_test}.txt\", \"w\") as f:\n",
    "                    f.write(row[\"url\"].replace(\"\", \" \")[1: -1])\n",
    "                valid_test = valid_test + 1\n",
    "    else:\n",
    "        if row[\"result\"] == 1:\n",
    "            if malicious > 10000:\n",
    "                pass\n",
    "            else:\n",
    "                with open(f\"{small_kaggle_set_folder}/{malicious_folder_name}/{malicious}.txt\", \"w\") as f:\n",
    "                    f.write(row[\"url\"].replace(\"\", \" \")[1: -1])\n",
    "                malicious = malicious + 1\n",
    "        else:\n",
    "            if valid > 50000:\n",
    "                pass\n",
    "            else:\n",
    "                with open(f\"{small_kaggle_set_folder}/{valid_folder_name}/{valid}.txt\", \"w\") as f:\n",
    "                    f.write(row[\"url\"].replace(\"\", \" \")[1: -1])\n",
    "                valid = valid + 1\n",
    "    i = i + 1\n",
    "    if i % 100000 == 0:\n",
    "        print(str(i) + \" done\")\n",
    "print(\"KAGGLE SMALL DATASET DONE\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5476516a8004>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  kaggle_data[\"url\"][i] = kaggle_data[\"url\"][i][:PADDING_SIZE]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 done\n",
      "60000 done\n",
      "90000 done\n",
      "120000 done\n",
      "150000 done\n",
      "180000 done\n",
      "210000 done\n",
      "240000 done\n",
      "270000 done\n",
      "300000 done\n",
      "330000 done\n",
      "360000 done\n",
      "390000 done\n",
      "420000 done\n",
      "450000 done\n",
      "KAGGLE SET PADDING DONE\n",
      "100000 done\n",
      "200000 done\n",
      "300000 done\n",
      "400000 done\n",
      "KAGGLE DATASET DONE\n"
     ]
    }
   ],
   "source": [
    "kaggle_data = pd.read_csv(raw_kaggle_data)\n",
    "kaggle_data = kaggle_data.drop('Unnamed: 0', axis=1)\n",
    "kaggle_data = kaggle_data.drop('label', axis=1)\n",
    "\n",
    "kaggle_data = kaggle_data.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "TOTAL_KAGGLE_VALID = (kaggle_data.result == 0).sum()\n",
    "TOTAL_KAGGLE_MALICIOUS = (kaggle_data.result == 1).sum()\n",
    "\n",
    "#Pad Kaggle_dataset\n",
    "kaggle_data = kaggle_data.copy()\n",
    "kaggle_data[\"url\"] = kaggle_data[\"url\"].str.pad(width=PADDING_SIZE, side='right', fillchar=' ')\n",
    "for i in range(len(kaggle_data)):\n",
    "    if len(kaggle_data[\"url\"][i]) > PADDING_SIZE:\n",
    "        kaggle_data[\"url\"][i] = kaggle_data[\"url\"][i][:PADDING_SIZE]\n",
    "    if i % 30000 == 0:\n",
    "        print(str(i) + \" done\")\n",
    "print(\"KAGGLE SET PADDING DONE\")\n",
    "\n",
    "#Create kaggle_dataset\n",
    "i = 0\n",
    "valid = 0\n",
    "malicious = 0\n",
    "test = 0\n",
    "malicious_test = 0\n",
    "valid_test = 0\n",
    "for index, row in kaggle_data.iterrows():\n",
    "    if valid > int(HISTORY_TRAIN_RATION * TOTAL_KAGGLE_VALID) and malicious > int(\n",
    "            HISTORY_TRAIN_RATION * TOTAL_KAGGLE_MALICIOUS) and test > int(\n",
    "        HISTORY_TRAIN_RATION * len(kaggle_data.index)):\n",
    "        break\n",
    "    elif valid > int(HISTORY_TRAIN_RATION * TOTAL_KAGGLE_VALID) and malicious > int(\n",
    "            HISTORY_TRAIN_RATION * TOTAL_KAGGLE_MALICIOUS) and test < int(\n",
    "        HISTORY_TRAIN_RATION * len(kaggle_data.index)):\n",
    "        if row[\"result\"] == 1:\n",
    "            with open(f\"{kaggle_test_set_folder}/{malicious_folder_name}/{malicious_test}.txt\", \"w\") as f:\n",
    "                f.write(row[\"url\"].replace(\"\", \" \")[1: -1])\n",
    "            malicious_test = malicious_test + 1\n",
    "            test = test + 1\n",
    "        else:\n",
    "            with open(f\"{kaggle_test_set_folder}/{valid_folder_name}/{valid_test}.txt\", \"w\") as f:\n",
    "                f.write(row[\"url\"].replace(\"\", \" \")[1: -1])\n",
    "            valid_test = valid_test + 1\n",
    "            test = test + 1\n",
    "    else:\n",
    "        if row[\"result\"] == 1:\n",
    "            with open(f\"{kaggle_set_folder}/{malicious_folder_name}/{malicious}.txt\", \"w\") as f:\n",
    "                f.write(row[\"url\"].replace(\"\", \" \")[1: -1])\n",
    "            malicious = malicious + 1\n",
    "        else:\n",
    "            with open(f\"{kaggle_set_folder}/{valid_folder_name}/{valid}.txt\", \"w\") as f:\n",
    "                f.write(row[\"url\"].replace(\"\", \" \")[1: -1])\n",
    "            valid = valid + 1\n",
    "    i = i + 1\n",
    "    if i % 100000 == 0:\n",
    "        print(str(i) + \" done\")\n",
    "print(\"KAGGLE DATASET DONE\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE URL DONE\n",
      "HISTORY SET PADDING DONE\n",
      "ERWANN DONE\n",
      "IRFAN DONE\n",
      "HISTORY SMALL DATASET DONE\n"
     ]
    }
   ],
   "source": [
    "#Make unique url cvs history\n",
    "with open('data/erwann_full.csv', 'r') as in_file, open(unique_erwann_history, 'w') as out_file:\n",
    "    seen = set()  # set for fast O(1) amortized lookup\n",
    "    for line in in_file:\n",
    "        if line in seen: continue  # skip duplicate\n",
    "\n",
    "        seen.add(line)\n",
    "        out_file.write(line)\n",
    "\n",
    "with open('data/irfan.csv', 'r') as in_file, open(unique_irfan_history, 'w') as out_file:\n",
    "    seen = set()  # set for fast O(1) amortized lookup\n",
    "    for line in in_file:\n",
    "        if line in seen: continue  # skip duplicate\n",
    "\n",
    "        seen.add(line)\n",
    "        out_file.write(line)\n",
    "print(\"UNIQUE URL DONE\")\n",
    "\n",
    "#Load Unique history set\n",
    "erwann_data = pd.read_csv(unique_erwann_history)\n",
    "irfan_data = pd.read_csv(unique_irfan_history)\n",
    "\n",
    "#Pad history_dataset\n",
    "erwann_data = erwann_data.copy()\n",
    "erwann_data[\"url\"] = erwann_data[\"url\"].str.pad(width=PADDING_SIZE, side='right', fillchar=' ')\n",
    "for i in range(len(erwann_data)):\n",
    "    if len(erwann_data[\"url\"][i]) > PADDING_SIZE:\n",
    "        erwann_data[\"url\"][i] = erwann_data[\"url\"][i][:PADDING_SIZE]\n",
    "\n",
    "irfan_data = irfan_data.copy()\n",
    "irfan_data[\"url\"] = irfan_data[\"url\"].str.pad(width=PADDING_SIZE, side='right', fillchar=' ')\n",
    "for i in range(len(irfan_data)):\n",
    "    if len(irfan_data[\"url\"][i]) > PADDING_SIZE:\n",
    "        irfan_data[\"url\"][i] = irfan_data[\"url\"][i][:PADDING_SIZE]\n",
    "print(\"HISTORY SET PADDING DONE\")\n",
    "\n",
    "#create history_set_folder\n",
    "valid = 0\n",
    "valid_test = 0\n",
    "temp_valid = 0\n",
    "for index, row in erwann_data.iterrows():\n",
    "    if temp_valid < int(HISTORY_TRAIN_RATION * len(erwann_data.index)):\n",
    "        with open(f\"{history_set_folder}/{valid_folder_name}/{valid}.txt\", \"w\") as f:\n",
    "            f.write(row[\"url\"].replace(\"\", \" \")[1: -1])\n",
    "        valid = valid + 1\n",
    "        temp_valid = temp_valid + 1\n",
    "    else:\n",
    "        with open(f\"{history_test_set_folder}/{valid_folder_name}/{valid_test}.txt\", \"w\") as f:\n",
    "            f.write(row[\"url\"].replace(\"\", \" \")[1: -1])\n",
    "        valid_test = valid_test + 1\n",
    "print(\"ERWANN DONE\")\n",
    "\n",
    "temp_valid = 0\n",
    "for index, row in irfan_data.iterrows():\n",
    "    if temp_valid < int(HISTORY_TRAIN_RATION * len(irfan_data.index)):\n",
    "        with open(f\"{history_set_folder}/{valid_folder_name}/{valid}.txt\", \"w\") as f:\n",
    "            f.write(row[\"url\"].replace(\"\", \" \")[1: -1])\n",
    "        valid = valid + 1\n",
    "        temp_valid = temp_valid + 1\n",
    "    else:\n",
    "        with open(f\"{history_test_set_folder}/{valid_folder_name}/{valid_test}.txt\", \"w\") as f:\n",
    "            f.write(row[\"url\"].replace(\"\", \" \")[1: -1])\n",
    "        valid_test = valid_test + 1\n",
    "print(\"IRFAN DONE\")\n",
    "print(\"HISTORY SMALL DATASET DONE\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMBINED TRAIN AND TEST SETS DONE\n"
     ]
    }
   ],
   "source": [
    "#combined dataset\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "valid_file_index = 0\n",
    "malicious_file_index = 0\n",
    "\n",
    "#history train valid\n",
    "for file in os.listdir(f\"{history_set_folder}/valid\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        shutil.copy(f\"{history_set_folder}/valid/{file}\", f\"{combine_set_folder}/valid/{valid_file_index}.txt\")\n",
    "        valid_file_index = valid_file_index + 1\n",
    "#history test valid\n",
    "for file in os.listdir(f\"{history_test_set_folder}/valid\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        shutil.copy(f\"{history_test_set_folder}/valid/{file}\", f\"{combine_test_set_folder}/valid/{valid_file_index}.txt\")\n",
    "        valid_file_index = valid_file_index + 1\n",
    "#small train valid\n",
    "for file in os.listdir(f\"{small_kaggle_set_folder}/valid\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        shutil.copy(f\"{small_kaggle_set_folder}/valid/{file}\", f\"{combine_set_folder}/valid/{valid_file_index}.txt\")\n",
    "        valid_file_index = valid_file_index + 1\n",
    "#small test valid\n",
    "for file in os.listdir(f\"{small_kaggle_test_set_folder}/valid\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        shutil.copy(f\"{small_kaggle_test_set_folder}/valid/{file}\", f\"{combine_test_set_folder}/valid/{valid_file_index}.txt\")\n",
    "        valid_file_index = valid_file_index + 1\n",
    "#small train malicious\n",
    "for file in os.listdir(f\"{small_kaggle_set_folder}/malicious\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        shutil.copy(f\"{small_kaggle_set_folder}/malicious/{file}\", f\"{combine_set_folder}/malicious/{malicious_file_index}.txt\")\n",
    "        malicious_file_index = malicious_file_index + 1\n",
    "#small test malicious\n",
    "for file in os.listdir(f\"{small_kaggle_test_set_folder}/malicious\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        shutil.copy(f\"{small_kaggle_test_set_folder}/malicious/{file}\", f\"{combine_test_set_folder}/malicious/{malicious_file_index}.txt\")\n",
    "        malicious_file_index = malicious_file_index + 1\n",
    "print(\"COMBINED TRAIN AND TEST SETS DONE\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}